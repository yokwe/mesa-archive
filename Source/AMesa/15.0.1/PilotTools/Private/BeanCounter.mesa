-- Copyright (C) 1986, 1987  by Xerox Corporation. All rights reserved.-- BeanCounter.mesa             by ET    24-Nov-87 12:53:21<<CONVERTED TO LABELLESS NOW PLAYING NEAR YOU!This is a hack that enumerates the page groups (runs) on the specified logical volume, and outputs statistics about it.  It does this by reading the primary etable on the logical volume and then enumerating the pagegroups therein -- thus giving run size information.  It registers itself as the exec command "CountBeans.~".  It creates a data file to keep it's file statistics in, and thus requires that the logical volume it runs on have at least 60 free pages on it.  This number is derived from (maxTableEntries*SIZE[TableEntry]/wordsPerPage = 5000*3/256 pages.  Note this data file adds one to the count of temporary files on the volume.  As the file etable entries are being read, a dot is printed out for each one.This implementation allows for 5000 total files on the logical volume indicated.  If there are more files than this number, then the statistics will be printed out for the allowed number of files and the program will be aborted short of the actual number of files.  (The data outputs even if incomplete to make it not a total waste of time...).  To increase this limit, increase the global maxTableEntries.  Note that you must necessarily insure the subject logical volume has additional free pages available for the increased data space...In this current labelless version, there is something wrong with free-page accounting.  There is no longer a free-page file type, nor a free-page-file which links together all the free pages.  So, within the information provided about the file system byu the etable file, there is no way to break down free pages runs.  A partial substitution is done here, so that at least the user can see the free page total count.  The free page total count is derived from the lv root page.  Additionally, since the total pages on the lv are derived from the free page count and the alloced page count, the total page count is also not available except as picked up from the lv root page.  There are accounting discrepancies here, sorry.>>	DIRECTORY  DiskChannel USING [    defaultTries, DoIO, IORequest, IOStatus, Handle, Create,    GetNextDrive, GetDriveAttributes, Drive, goodCompletion,    nullDrive, nullHandle],  Environment USING [PageNumber, wordsPerPage],  ETable USING [BucketHandle, BucketHeader, ETable, ETableHandle,    ETableHeader, FileHeader, FileHeaderHandle, PageGroup],  Exec USING [AddCommand, CheckForAbort, EndOfCommandLine, ExecProc,    FreeTokenString, GetToken, Handle, OutputProc, RemoveCommand],  File USING [ID, Type, nullID],  Format USING [Decimal, LongDecimal, Octal, StringProc],  LogicalVolumeFormat USING [Descriptor],  PhysicalVolume USING [GetContainingPhysicalVolume, ID, PageNumber],  PilotFileTypes USING [tAnonymousFile, tFreePage, tVolumeAllocationMap,    tVMBackingFile],  Space USING [LongPointerFromPage,    PageFromLongPointer, PagesFromWords, ScratchMap, Unmap],  SpecialVolume USING [GetNextSubVolume, nullSubVolume, SubVolume],  String USING [Equivalent],  VM USING [Interval, PageCount],  Volume USING [GetLabelString, GetNext, ID, maxNameLength, nullID,    Unknown];BeanCounter: PROGRAM  IMPORTS    Exec, Format, DiskChannel, PhysicalVolume,    Space, SpecialVolume, String, Volume =  BEGIN--*************************************---- Global variables.--*************************************--  exceededTable: BOOLEAN ¬ FALSE;  processingNormal: BOOLEAN ¬ TRUE;	-- gets FALSE when overflow etables are hit.  firstPageOfOverflow: BOOLEAN ¬ TRUE;	-- gets FALSE after first overflow page.  processingFinished: BOOLEAN ¬ FALSE;  totalNonOverflowBuckets: CARDINAL ¬ 0;  currentNumberFilesInOverflow: CARDINAL ¬ 0;    -- This is a table, indexed by fileID's.  Each fileID entry has a count  --  of the number of page groups in that file.  -- Entries that are indexed by File.nullID are unused entries.  -- SIZE[TableEntry] = 3 words.  maxTableEntries: CARDINAL = 5000;  TableEntry: TYPE = RECORD[    fileID: File.ID,    runs: CARDINAL];  table: LONG POINTER TO ARRAY [1..maxTableEntries] OF TableEntry;  lastEntry: CARDINAL ¬ 0; -- index of last entry filled in table.    -- These are disk page buffers used by the data-acquisition routine.  etableBuffer: LONG POINTER TO VM.Interval;		-- a three page buffer  overflowBuffer: LONG POINTER TO VM.Interval;		-- a four page buffer  dataBuffer: LONG POINTER TO VM.Interval;		-- a one page buffer    -- Statistic variables that will be printed out.  totalNumberPages: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberAllocatedPages: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberFreePages: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberFiles: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberFilesInOverflow: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberTemporaryFiles: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberAnonymousFiles: LONG CARDINAL ¬ 0; -- on this LV.  totalNumberRuns, totalVMBNumberRuns, totalVAMNumberRuns: LONG CARDINAL ¬ 0; -- on this LV.  totalETableFileNumberRuns: CARDINAL ¬ 0; -- on this LV.  totalETableFileCopyNumberRuns: CARDINAL ¬ 0; -- on this LV.  maxAllocatedRunSize: LONG CARDINAL ¬ 0; -- on this LV.  maxFreeRunSize: LONG CARDINAL ¬ 0; -- on this LV.  averageNumberRuns: LONG CARDINAL ¬ 0; -- per file on this LV.  maxNumberRuns: RECORD [ fileID: File.ID ¬ File.nullID,                          pages: LONG CARDINAL ¬ 0]; -- per file on this LV.  curveSize: CARDINAL = 16; -- inclusive.  CurveType: TYPE = ARRAY [1..curveSize] OF CARDINAL;  fileRunCurve: CurveType ¬ ALL[0]; -- histogram of pagegroups in files  freePGCurve: CurveType ¬ ALL[0]; -- free across entire LV.  pgCurve: CurveType ¬ ALL[0]; -- non-free across entire LV.  	-- pgCurve[ 1] = # of runs that are 1 page.	-- pgCurve[ 2] = # of runs that are 2 pages.  	-- pgCurve[ 3] = # of runs that are 3 pages.	-- pgCurve[ 4] = # of runs that are 4 pages.  	-- pgCurve[ 5] = # of runs that are 5 pages.	-- pgCurve[ 6] = # of runs that are 6 pages.  	-- pgCurve[ 7] = # of runs that are 7 pages.	-- pgCurve[ 8] = # of runs that are 8 pages.	-- pgCurve[ 9] = # of runs that are 9 pages.	-- pgCurve[10] = # of runs at least   9 but less than  20 pages.	-- pgCurve[11] = # of runs at least  20 but less than  30 pages.	-- pgCurve[12] = # of runs at least  30 but less than  40 pages.	-- pgCurve[13] = # of runs at least  40 but less than  50 pages.	-- pgCurve[14] = # of runs at least  50 but less than 200 pages.	-- pgCurve[15] = # of runs at least 200 but less than  1K pages.	-- pgCurve[16] = # of runs at least 1K pages.impossibleEndcase: PUBLIC ERROR = CODE;abortThyself: SIGNAL = CODE;--*************************************---- User abortabilityness, thank you.--*************************************--  AbortMe: PROCEDURE =    BEGIN SIGNAL abortThyself END;--*************************************---- Zero out all global data (in case the program is run twice).--*************************************--  InitializeGlobals: PROCEDURE =    BEGIN    exceededTable ¬ processingFinished ¬ FALSE;    processingNormal ¬ firstPageOfOverflow ¬ TRUE;    currentNumberFilesInOverflow ¬ 0;    etableBuffer ¬ Space.ScratchMap[3];    overflowBuffer ¬ Space.ScratchMap[4];    dataBuffer ¬ Space.ScratchMap[1];    table ¬ Space.ScratchMap[      Space.PagesFromWords[LONG[maxTableEntries]*SIZE[TableEntry]]];    lastEntry ¬ 0;    totalNumberPages ¬ 0;    totalNumberAllocatedPages ¬ 0;    totalNumberFreePages ¬ 0;    totalNumberFiles ¬ 0;    totalNumberFilesInOverflow ¬ 0;    totalNumberTemporaryFiles ¬ 0;    totalNumberAnonymousFiles ¬ 0;    totalNumberRuns ¬ 0;    totalVMBNumberRuns ¬ totalVAMNumberRuns ¬ 0;    totalETableFileNumberRuns ¬ totalETableFileCopyNumberRuns ¬ 0;    maxAllocatedRunSize ¬ 0;    maxFreeRunSize ¬ 0;    averageNumberRuns ¬ 0;    maxNumberRuns ¬ [File.nullID, 0];    fileRunCurve ¬ ALL[0];    pgCurve ¬ ALL[0];    freePGCurve ¬ ALL[0];    END; --InitializeGlobals----************************************************---- Bump the appropriate curve point according to the curve rules--  mentioned in the global declaration above.--************************************************--  InsertInCurve: PROCEDURE [    curve: LONG POINTER TO CurveType, data: CARDINAL] =     BEGIN    IF data = 0 THEN RETURN;    IF data < 10 THEN      curve­[data] ¬ curve­[data] + 1;    IF data >=10 AND data < 20 THEN      curve­[10] ¬ curve­[10] + 1;    IF data >=20 AND data < 30 THEN      curve­[11] ¬ curve­[11] + 1;    IF data >=30 AND data < 40 THEN      curve­[12] ¬ curve­[12] + 1;    IF data >=40 AND data < 50 THEN      curve­[13] ¬ curve­[13] + 1;    IF data >=50 AND data < 200 THEN      curve­[14] ¬ curve­[14] + 1;    IF data >=200 AND data < 1000 THEN      curve­[15] ¬ curve­[15] + 1;    IF data >=1000 THEN      curve­[16] ¬ curve­[16] + 1;    END;  --InsertInCurve--  --************************************************---- Walk through all the etables in the specified bucket, collecting-- pagegroup and file data for each etable.--************************************************--        -- enter <inuse etable> stats into table.  TallyInUseETable: PROCEDURE [h: Exec.Handle, et: ETable.ETableHandle] =    BEGIN        -- internal proc.  Print text to the exec.    Out: Format.StringProc = Exec.OutputProc[h];          --internal proc.  walk thru all the pagegroups in an etable.    EnumeratePageGroups: PROCEDURE [et: ETable.ETableHandle,      totalTallyPtr, maxTallyPtr: LONG POINTER TO LONG CARDINAL,      curvePtr: LONG POINTER TO CurveType] =        BEGIN	-- for each page group:	FOR pgIndex: CARDINAL IN [0..et.header.howManyGroups) DO	  size: CARDINAL ¬ et.pageGroups[pgIndex].count;	  totalTallyPtr­ ¬ totalTallyPtr­ + size;	  IF size > maxTallyPtr­ THEN maxTallyPtr­ ¬ size;	  InsertInCurve[curvePtr, CARDINAL[size]];	  ENDLOOP;        END; --internal EnumeratePageGroups--        -- internal proc. put etable into this hack's table.    -- Maintains UNsorted list of File.IDs, returns index of thing last added.    -- Note that the next unused entry AFTER newLastEntry is initialized, too.    InsertFileInTable: PROCEDURE [lastEntry: CARDINAL]       RETURNS [newLastEntry: CARDINAL] =      BEGIN<<        FOR file: CARDINAL IN [1..lastEntry] DO -- search for any old entry.	    IF table­[file].fileID = et.header.fileID THEN	      {Out["duplicate FileID"L]; AbortMe[]};            ENDLOOP;>>      IF lastEntry + 1 > maxTableEntries THEN {exceededTable ¬ TRUE; RETURN};        newLastEntry ¬ lastEntry + 1;		-- add new entry.        table­[newLastEntry] ¬ [et.header.fileID, et.header.howManyGroups];        IF newLastEntry # maxTableEntries THEN    -- clear entry ahead of it.          table­[newLastEntry+1] ¬ [File.nullID, 0];        END; -- internal InsertFileInTable --    -- local code    IF et.header.type = PilotFileTypes.tFreePage THEN  -- it's all the free runs    -- labelless pilot doesn't have this file type.  free pages are tracked in the VAM.      ERROR    <<EnumeratePageGroups[	et, @totalNumberFreePages, @maxFreeRunSize, @freePGCurve] >>    ELSE -- it's an allocated file      BEGIN      totalNumberFiles ¬ totalNumberFiles + 1;      IF (totalNumberFiles MOD 100) = 0 THEN Out["%"L]      ELSE IF (totalNumberFiles MOD 10) = 0 THEN Out["!"L]      ELSE Out["."L];      IF et.header.temporary THEN	totalNumberTemporaryFiles ¬ totalNumberTemporaryFiles + 1;      SELECT et.header.type FROM	PilotFileTypes.tVolumeAllocationMap => 	  totalVAMNumberRuns ¬ et.header.howManyGroups;	PilotFileTypes.tVMBackingFile => 	  totalVMBNumberRuns ¬ et.header.howManyGroups;	PilotFileTypes.tAnonymousFile => 	  totalNumberAnonymousFiles ¬ totalNumberAnonymousFiles + 1;	ENDCASE => NULL;      totalNumberRuns ¬ totalNumberRuns + et.header.howManyGroups;      EnumeratePageGroups[	et, @totalNumberAllocatedPages, @maxAllocatedRunSize, @pgCurve];      lastEntry ¬ InsertFileInTable[lastEntry];      IF exceededTable THEN	Out["\nLimit of table is reached; premature quit."L];      END;    END; --TallyInUseETable--  EnumerateETables: PROCEDURE [h: Exec.Handle, etfBucket: ETable.BucketHandle] =    BEGIN    Out: Format.StringProc = Exec.OutputProc[h];    et: ETable.ETableHandle ¬ LOOPHOLE[@etfBucket.eTables];<<>>endOfBucket: LONG ORDERED POINTER ¬      LOOPHOLE[@etfBucket[etfBucket.header.firstFree - SIZE[ETable.ETableHeader]]];    --     (if the bucket header says there are no files then LOOP    --     (step from etable to etable within the bucket    --     (increment step = ETableHeader.howManyGroups * SIZE[PageGroup]    --     (for each etable, record fileID's and howManyGroups)    IF etfBucket.header.firstFree = LOOPHOLE[SIZE[ETable.BucketHeader]] THEN      RETURN;	-- the bucket is empty    totalNumberFilesInOverflow ¬      totalNumberFilesInOverflow + etfBucket.header.eTablesInOverflowCount;<<>>WHILE LOOPHOLE[et, LONG ORDERED POINTER] < endOfBucket DO    <<WHILE et.header.howManyGroups # 0 DO>>      IF et.header.fileID # File.nullID THEN	-- it's an inuse etable        BEGIN        TallyInUseETable[h, et];	IF et.header.howManyGroups = 0 THEN Out[" snort "L]; --??--	et ¬ et + LOOPHOLE[SIZE[ETable.ETableHeader]] + 	  LOOPHOLE[et.header.howManyGroups * SIZE[ETable.PageGroup]];	IF Exec.CheckForAbort[h] THEN AbortMe[];	END      ELSE					-- it's an (impossible) free etable        ERROR;      IF exceededTable THEN RETURN;      ENDLOOP;  -- normal et iteration --    END; -- EnumerateETables --  EnumerateOverflow: PROCEDURE [h: Exec.Handle, etfBucket: ETable.BucketHandle] =    BEGIN    Out: Format.StringProc = Exec.OutputProc[h];    et: ETable.ETableHandle ¬ LOOPHOLE[etfBucket];    endOfOverflowBuffer: LONG ORDERED POINTER ¬ LOOPHOLE[--it's a four page buffer      Space.LongPointerFromPage[Space.PageFromLongPointer[etfBucket] + 4]];    --   if the bucket header says there are no files then LOOP    --   step from etable to etable within overflow    --     (if the etable is <type free ETableHeader> then    --     (  increment step = ETableHeader.length    --     (else <type inuse ETableHeader>    --     (  increment step = ETableHeader.howManyGroups * SIZE[PageGroup]    --     (for each etable, record fileID's and howManyGroups)    IF firstPageOfOverflow THEN				-- skip bucket header      {et ¬ LOOPHOLE[@etfBucket.eTables]; firstPageOfOverflow ¬ FALSE};<<>><<WHILE et < @etfBucket[etfBucket.header.freeSpace] DO>>    WHILE currentNumberFilesInOverflow < totalNumberFilesInOverflow DO      IF LOOPHOLE[et, LONG ORDERED POINTER] >= endOfOverflowBuffer THEN	RETURN;						-- need next four pages!      IF et.header.fileID # File.nullID THEN		-- it's an inuse etable        BEGIN        TallyInUseETable[h, et];	currentNumberFilesInOverflow ¬ currentNumberFilesInOverflow + 1;	IF et.header.howManyGroups = 0 THEN Out[" snort "L]; --??--	et ¬ et + LOOPHOLE[SIZE[ETable.ETableHeader]] + 	  LOOPHOLE[et.header.howManyGroups * SIZE[ETable.PageGroup]];	IF Exec.CheckForAbort[h] THEN AbortMe[];	END      ELSE 						-- it's a free etable	et ¬ et + LOOPHOLE[et.header.length];      IF exceededTable THEN RETURN;      REPEAT FINISHED => processingFinished ¬ TRUE;      ENDLOOP;  -- overflow et iteration --    END; -- EnumerateOverflow -- --************************************************---- Fill the FileTable with page run info for each file on the LV.--************************************************--  InitializeTable: PROCEDURE [h: Exec.Handle] =     BEGIN        -- internal proc.  Print text to the exec.    Out: Format.StringProc = Exec.OutputProc[h];        -- internal proc.  get lvRootPage. assumes at least one LV.    -- has to first get LV ID from name, then get LV size from PV.    GetDiskInfo: PROCEDURE RETURNS [      found: BOOLEAN ¬ FALSE, drive: DiskChannel.Drive,      lvRootPage: PhysicalVolume.PageNumber] =      BEGIN      index: CARDINAL ¬ 0;      reqLVname, switches: LONG STRING;      myLVname: LONG STRING _ [Volume.maxNameLength];      myLVID: Volume.ID _ Volume.GetNext[Volume.nullID, [TRUE, TRUE, TRUE, TRUE]];      myPVID: PhysicalVolume.ID;      myLV: SpecialVolume.SubVolume;      -- get drive.      FOR drive ¬ DiskChannel.GetNextDrive[DiskChannel.nullDrive],        DiskChannel.GetNextDrive[drive] UNTIL drive = DiskChannel.nullDrive  DO        IF index = DiskChannel.GetDriveAttributes[drive].deviceOrdinal THEN          {found ¬ TRUE; EXIT;};        ENDLOOP;      -- get LV ID from supplied LV name.      IF Exec.EndOfCommandLine[h] THEN GOTO Quit;      [reqLVname, switches] _ Exec.GetToken[h];      Volume.GetLabelString[myLVID, myLVname        ! Volume.Unknown => GOTO Quit];      WHILE myLVID # Volume.nullID AND NOT String.Equivalent[reqLVname, myLVname] DO        myLVID _ Volume.GetNext[myLVID, [TRUE, TRUE, TRUE, TRUE]];        Volume.GetLabelString[myLVID, myLVname ! Volume.Unknown => GOTO Quit];        ENDLOOP;      switches _ Exec.FreeTokenString[switches];      reqLVname _ Exec.FreeTokenString[reqLVname];      IF myLVID = Volume.nullID THEN GOTO Quit;     -- get LV size from PV and LV ID.      myPVID ¬ PhysicalVolume.GetContainingPhysicalVolume[myLVID];      myLV ¬ SpecialVolume.GetNextSubVolume[myPVID, SpecialVolume.nullSubVolume];      UNTIL myLV.lvID = myLVID DO        myLV ¬ SpecialVolume.GetNextSubVolume[myPVID, myLV];	ENDLOOP;      lvRootPage ¬ myLV.firstPVPageNumber;      EXITS      Quit => {RETURN[found, drive, 0]};      END; --internal GetDiskInfo--    -- internal proc.  read pages in from the disk.    ReadPage: PROCEDURE [channel: DiskChannel.Handle,      pvPage: PhysicalVolume.PageNumber,      vmPage: Environment.PageNumber, vmCount: VM.PageCount]      RETURNS [success: BOOLEAN ¬ TRUE] =        BEGIN        req: DiskChannel.IORequest;        status: DiskChannel.IOStatus ¬ LOOPHOLE[0];	countDone: LONG CARDINAL ¬ 0;        -- read pvPage into vmPage.        WHILE (status # DiskChannel.goodCompletion) OR (countDone # vmCount) DO	  IF Exec.CheckForAbort[h] THEN AbortMe[];          req ¬ [              command: read,              diskPage: pvPage, memoryPage: vmPage,              tries: DiskChannel.defaultTries,	      useSamePage: FALSE, count: vmCount              ];          [status, countDone] ¬ DiskChannel.DoIO[channel, @req];          IF status ~= DiskChannel.goodCompletion THEN {Out[" burp "L]; LOOP};	  ENDLOOP;        END; -- internal ReadPage --    -- local variables    channel: DiskChannel.Handle ¬ DiskChannel.nullHandle;    drive: DiskChannel.Drive ¬ DiskChannel.nullDrive;    diskOk: BOOLEAN ¬ FALSE;    lvRootPage, etfHeaderPage, etfETablePage: PhysicalVolume.PageNumber ¬ 0;    lvDescriptor: LONG POINTER TO LogicalVolumeFormat.Descriptor ¬ NIL;    etfHeader: ETable.FileHeaderHandle ¬ NIL;    etfETable: ETable.ETableHandle ¬ NIL;    preImageSize: LONG CARDINAL ¬ 0;    maxETableSize: CARDINAL ¬ 0;    headerOffset: LONG CARDINAL ¬ 0;    -- read lv root page.    [diskOk, drive, lvRootPage] ¬ GetDiskInfo[];    IF ~diskOk THEN {Out[" drive not ready"L]; AbortMe[]};  -- cannot get to drive.    channel ¬ DiskChannel.Create[drive];    IF lvRootPage = 0 THEN      {Out["\nBad volume specified."L]; RETURN};    IF ~ReadPage[channel, lvRootPage, Space.PageFromLongPointer[dataBuffer], 1] THEN      {Out[" can't read lv root"L]; RETURN};    lvDescriptor ¬ LOOPHOLE[dataBuffer];    totalNumberPages ¬ lvDescriptor.volumeSize;    totalNumberFreePages ¬ lvDescriptor.freePageCount;    -- read etable file header.    etfHeaderPage ¬ LOOPHOLE[      lvDescriptor.primaryETableStartPage, PhysicalVolume.PageNumber]      + lvRootPage;    lvDescriptor ¬ NIL;-- can't use this after ReadPage smashes it with etfHeaderPage    IF ~ReadPage[channel, etfHeaderPage, Space.PageFromLongPointer[dataBuffer], 1] THEN      {Out[" can't read etable file header"L]; RETURN};    etfHeader ¬ LOOPHOLE[dataBuffer];    totalNonOverflowBuckets ¬ etfHeader.numberOfBuckets;    preImageSize ¬ etfHeader.preImageSize;    maxETableSize ¬ etfHeader.maxETableSize;    headerOffset ¬ SIZE[ETable.FileHeader]/Environment.wordsPerPage +      preImageSize + 2*maxETableSize;    -- read etable file etable COPY (three pages!).  Discarded right away.    etfETablePage ¬ LOOPHOLE[      etfHeader.copyETFHeader.myFirstETablePage, PhysicalVolume.PageNumber]      + lvRootPage;    IF ~ReadPage[channel, etfETablePage, Space.PageFromLongPointer[etableBuffer], 3] THEN      {Out[" can't read etable file etable"L]; RETURN};    etfETable ¬ LOOPHOLE[etableBuffer];    totalETableFileCopyNumberRuns ¬ etfETable.header.howManyGroups;    -- read etable file etable (three pages!).    etfETablePage ¬ LOOPHOLE[      etfHeader.primaryETFHeader.myFirstETablePage, PhysicalVolume.PageNumber]      + lvRootPage;    IF ~ReadPage[channel, etfETablePage, Space.PageFromLongPointer[etableBuffer], 3] THEN      {Out[" can't read etable file etable"L]; RETURN};    etfETable ¬ LOOPHOLE[etableBuffer];    totalETableFileNumberRuns ¬ etfETable.header.howManyGroups;    -- enumerate the page groups in the etable file.    etfHeader ¬ NIL;-- can't use this after ReadPage smashes it with etfPage    FOR etfPageGroups: CARDINAL IN [0..totalETableFileNumberRuns) DO        overflowBufferCounter: CARDINAL ¬ 0;	currentNonOverflowBuckets: CARDINAL ¬ 0;    	firstPageInRun: PhysicalVolume.PageNumber	  ¬ etfETable.pageGroups[etfPageGroups].volumePage + lvRootPage;	lastPageInRun: PhysicalVolume.PageNumber	  ¬ firstPageInRun + etfETable.pageGroups[etfPageGroups].count;	IF etfPageGroups = 0 THEN firstPageInRun ¬ firstPageInRun + headerOffset;        IF Exec.CheckForAbort[h] THEN AbortMe[];	-- enumerate the buckets in each page group in the etable file	FOR etfPage: PhysicalVolume.PageNumber IN [firstPageInRun..lastPageInRun) DO	   etfPagePtr: ETable.BucketHandle ¬ NIL;	   IF processingFinished THEN EXIT;	   IF processingNormal THEN		--read one page at a time	     BEGIN	     IF ~ReadPage[channel, etfPage,Space.PageFromLongPointer[dataBuffer], 1] THEN               {Out[" can't read page in etable file"L]; LOOP};	     etfPagePtr ¬ LOOPHOLE[dataBuffer];	     EnumerateETables[h, etfPagePtr];	     currentNonOverflowBuckets ¬ currentNonOverflowBuckets + 1;	     IF currentNonOverflowBuckets = totalNonOverflowBuckets THEN	       processingNormal ¬ FALSE;	     END	   ELSE	-- processing Overflow		++read four pages at a time	     BEGIN	     IF ~ReadPage[channel, etfPage,	       Space.PageFromLongPointer[overflowBuffer]+overflowBufferCounter, 1] THEN               {Out[" can't read page in etable overflow"L]; RETURN};	     IF overflowBufferCounter = 3 THEN	       {EnumerateOverflow[h, LOOPHOLE[overflowBuffer]];	        overflowBufferCounter ¬ 0}	     ELSE overflowBufferCounter ¬ overflowBufferCounter + 1;	     END;	   IF Exec.CheckForAbort[h] THEN AbortMe[];	   IF exceededTable THEN EXIT;	   ENDLOOP; --etfPage--	ENDLOOP; --etfPageGroups--    IF NOT processingFinished AND NOT exceededTable THEN      Out[" no more etable file pages, yet still more overflow"L];    END; --InitializeTable--      --************************************************---- Computes statistics for every file entered in the table.--************************************************--  EnumerateTable: PROCEDURE =     BEGIN    file: CARDINAL ¬ 1;    FOR file IN [1..lastEntry] DO -- for every file (every non-free page)      InsertInCurve[@fileRunCurve, table­[file].runs];      IF table­[file].runs > maxNumberRuns.pages THEN        maxNumberRuns ¬ [table­[file].fileID, table­[file].runs];      ENDLOOP; -- for every file (every non-free page)    averageNumberRuns ¬ totalNumberRuns/totalNumberFiles;    END; --EnumerateTable--        --************************************************---- Prints statistics for every file entered in the table.--************************************************--  PrintTable: PROCEDURE [h: Exec.Handle] =     BEGIN    usableFileID: TYPE = RECORD[a, b: CARDINAL];    Out: Format.StringProc = Exec.OutputProc[h];        Out["\nTotal PAGES, ALLOCATED, FREE on this LV: "L];    	Format.LongDecimal[Out, totalNumberPages]; Out[" , "L];    	Format.LongDecimal[Out, totalNumberAllocatedPages]; Out[" , "L];    	Format.LongDecimal[Out, totalNumberFreePages];    Out["\nTotal FILES, OVERFLOW, TEMPORARY, ANONYMOUS on this LV: "L];    	Format.LongDecimal[Out, totalNumberFiles]; Out[" , "L];    	Format.LongDecimal[Out, totalNumberFilesInOverflow]; Out[" , "L];    	Format.LongDecimal[Out, totalNumberTemporaryFiles]; Out[" , "L];    	Format.LongDecimal[Out, totalNumberAnonymousFiles];    Out["\nTotal number of runs on this LV: "L];    	Format.LongDecimal[Out, totalNumberRuns];    Out["\nBiggest ALLOCATED, FREE run size on this LV: "L];    	Format.LongDecimal[Out, maxAllocatedRunSize]; Out[" , "L];    	Format.LongDecimal[Out, maxFreeRunSize];    Out["\nAve and Max number of runs in a file on this LV: "L];    	Format.LongDecimal[Out, averageNumberRuns]; Out[" and "L];    	Format.LongDecimal[Out, maxNumberRuns.pages];    Out["\n		(file ID of most fragmented file is "L];        	Format.Octal[Out, 	   LOOPHOLE[maxNumberRuns.fileID, usableFileID].a]; Out[" , "L];    	Format.Octal[Out, 	   LOOPHOLE[maxNumberRuns.fileID, usableFileID].b]; Out["B)"L];    Out["\nVMBACKINGFILE, VAM, ETABLEFILE, ETABLEFILE COPY run count: "L];	Format.LongDecimal[Out, totalVMBNumberRuns]; Out[" , "L];	Format.LongDecimal[Out, totalVAMNumberRuns]; Out[" , "L];	Format.Decimal[Out, totalETableFileNumberRuns]; Out[" , "L];	Format.Decimal[Out, totalETableFileCopyNumberRuns];    Out["\nRun distribution across entire LV"L];    Out["\n		alloc	free  runs-in-file"L];    Out["\n	size	count	count	count"L];    Out["\n	1	"L]; Format.Decimal[Out, pgCurve[ 1]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 1]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 1]];    Out["\n	2	"L]; Format.Decimal[Out, pgCurve[ 2]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 2]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 2]];    Out["\n	3	"L]; Format.Decimal[Out, pgCurve[ 3]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 3]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 3]];    Out["\n	4	"L]; Format.Decimal[Out, pgCurve[ 4]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 4]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 4]];    Out["\n	5	"L]; Format.Decimal[Out, pgCurve[ 5]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 5]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 5]];    Out["\n	6	"L]; Format.Decimal[Out, pgCurve[ 6]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 6]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 6]];    Out["\n	7	"L]; Format.Decimal[Out, pgCurve[ 7]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 7]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 7]];    Out["\n	8	"L]; Format.Decimal[Out, pgCurve[ 8]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 8]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 8]];    Out["\n	9	"L]; Format.Decimal[Out, pgCurve[ 9]]; Out["	"L]; Format.Decimal[Out, freePGCurve[ 9]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[ 9]];    Out["\n = 10 & < 20	"L]; Format.Decimal[Out, pgCurve[10]]; Out["	"L]; Format.Decimal[Out, freePGCurve[10]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[10]];    Out["\n = 20 & < 30	"L]; Format.Decimal[Out, pgCurve[11]]; Out["	"L]; Format.Decimal[Out, freePGCurve[11]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[11]];    Out["\n = 30 & < 40	"L]; Format.Decimal[Out, pgCurve[12]]; Out["	"L]; Format.Decimal[Out, freePGCurve[11]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[12]];    Out["\n = 40 & < 50	"L]; Format.Decimal[Out, pgCurve[13]]; Out["	"L]; Format.Decimal[Out, freePGCurve[11]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[13]];    Out["\n = 50 & <200	"L]; Format.Decimal[Out, pgCurve[14]]; Out["	"L]; Format.Decimal[Out, freePGCurve[12]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[14]];    Out["\n =200 & < 1K	"L]; Format.Decimal[Out, pgCurve[15]]; Out["	"L]; Format.Decimal[Out, freePGCurve[13]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[15]];    Out["\n	>=1K	"L]; Format.Decimal[Out, pgCurve[16]]; Out["	"L]; Format.Decimal[Out, freePGCurve[14]]; Out["	"L]; Format.Decimal[Out, fileRunCurve[16]];    END; --PrintTable----************************************************---- Cleanup routine.-- This routine unmaps the table's space and it's data buffers.--************************************************--  Cleanup: PROCEDURE =    BEGIN    [] ¬ Space.Unmap[etableBuffer];    [] ¬ Space.Unmap[overflowBuffer];    [] ¬ Space.Unmap[dataBuffer];    [] ¬ Space.Unmap[table];    END; --Cleanup----************************************************---- Main routine.--  InitializeGlobals does a failsafe clear of all the globals.--  InitializeTable sets up the table of page run counts for each file.--  EnumerateTable counts the number of page runs in the current LV.--  PrintTable prints the numbers EnumerateTable came up with.--  Cleanup unmaps data buffers and the table.--************************************************--        Main: Exec.ExecProc =      BEGIN      ENABLE {UNWIND => NULL;              abortThyself => GO TO Aborted};      InitializeGlobals[];      InitializeTable[h];      IF lastEntry # 0 THEN       {EnumerateTable[];        PrintTable[h]};      Cleanup[];      EXITS Aborted => {Cleanup[];	 		h.OutputProc[]["\n ..aborted."L]};      END;          Unload: Exec.ExecProc = {h.RemoveCommand["CountBeans.~"L]};        Help: Exec.ExecProc = {      h.OutputProc[]["This is a hack that enumerates the page groups        on the current logical volume, and outputs statistics about it.	It does this by reading the first label of each run on the	logical volume and then doing a label verify on the remainder	of the run -- thus giving run size information.  It registers	itself as the exec command 'CountBeans.~'.  To run, it requires	the logical volume have about 60 free pages on it.  As the	pages are being read, a dot is printed out for every 100 of	them."L]};        --************************************************---- Mainline code--************************************************--    Exec.AddCommand[name: "CountBeans.~"L, proc: Main, help: Help, unload: Unload];          END...  -- LOG--  6-Feb-86 23:15:00 KEK created file-- 11-Feb-86 11:19:00 KEK added runs-in-file histogram (fileRunCurve) stuff.  also add file ID of most fragmented file.-- 13-Feb-86 13:29:34 KEK add LV argument, so can run across LV's other than the current one.-- 24-Nov-87 12:53:33 ET  Broke curve piece 20-50 down to 20-30,30-40,40-50.