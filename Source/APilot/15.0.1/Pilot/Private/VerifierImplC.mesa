--Copyright (C) 1987, 1988 by Xerox Corporation.  All rights reserved.--VerifierImplC.mesa          30-Jul-88 17:46:45 by RSVDIRECTORY  BackingStore USING [Run],   DiskBackingStore USING [    BSDataFromDiskData, ChannelHandle, Data, FilePageHigh, FilePageLow,    Transfer, UnpackFilePageNumber],   DiskChannel USING [defaultTries, DoIO, Handle, IORequest, IOStatus],  Environment USING [PageCount, PageFromLongPointer, PageNumber, wordsPerPage],  ETable USING [    BucketHandle, ETableHandle, ETableHeader, FreeSpaceInOverflow,    LVBucketInfo, PageGroup, PageGroupHandle, WhichETableFile],  ETableInternal USING [    CreateETableInternal, DeleteETableInternal, FindETable,    GetPageGroupInternal, GetSize, maxPageGroupSize, overflowBufferSize,     ReplaceOldETableInternal, WhereIsFilePageOnVolume],  File USING [File, ID, nullFile, nullID, PageCount, PageNumber, Type],   FileInternal USING [FileID],   FileLock USING [lockingEnabled, nullLockHandle],  FileTypes USING [tUntypedFile],  Inline USING [LongCOPY, LowHalf],  KernelVolume USING [],   KernelFile USING [Descriptor, PageGroup],   LogicalVolumeFormat USING [    Handle, MaxEntriesInRootDirectory, MaxPagesInRootDirectory, RootDirectory,    RootDirSeal, RootDirVersion, rootPageSize],   PhysicalVolume USING [PageNumber],  PhysicalVolumeFormat USING [markerPageSize],   PilotFileTypes USING[tRootDirectory, tScavengerLog],   RuntimeInternal USING [Bug],  Scavenger USING [    currentLogVersion, Error, FileEntry, Header, LogSeal, noneDeleted],  ScavengerUtilities USING [FreeLVMarkerPages, GatherLVMarkerPages, SVInfo],  Space USING [    Allocate, Deallocate, Error, InsufficientSpace, Interval,    PageFromLongPointer],   SpecialFile USING [GetBackingStoreRun],   System USING [GetGreenwichMeanTime],    VerifierInternal USING [    AddToErrorList, bucketOverflowList, diskChannel, errorList,     errorListOverflowed,ETableErrorType,firstPVPageOfLV, GetDiskIOInfo,    IOType, LogInfo, localScavengerLogFileExists,     maximumNumberOfErrorsInErrorList, numberOfErrorsInErrorList, numberOfFiles,     numberOfFilesInFileList, ReadPage, skipClientPageCorrections, ValidateETable,    ValidPage, WritePage],   VM USING [    BackingStoreRuns, ForceOut, Interval, Map, nullInterval, ScratchMap, Unmap],   VolAllocMap USING [AllocPageGroup, FreePageGroup],   VolTable USING [GetNextSV, GetSVToken, LVToken, MapMarkerPage, UnmapMarkerPage,    SVDesc, SVToken],  Volume USING [ID, InsufficientSpace, PageCount, PageNumber]; VerifierImplC: MONITOR  IMPORTS     DiskBackingStore, DiskChannel, ETableInternal, FileLock, Inline,    RuntimeInternal, Scavenger, ScavengerUtilities, Space, SpecialFile,    System, VerifierInternal, VolAllocMap, VolTable, Volume, VM  EXPORTS    VerifierInternal =     BEGIN    OPEN ETI: ETableInternal, PVF: PhysicalVolumeFormat,     ET: ETable, LVF: LogicalVolumeFormat, VI: VerifierInternal;      Bug: PROCEDURE [bug: BugType] = {RuntimeInternal.Bug[bug]};   BugType: TYPE = {    allocationError, badInfoFromVFM, fileSystemError, impossibleEndcase,     impossibleFaceStatus, impossibleProblemType, invalidChannel,    invalidDriveState, logicError, neededFileNotInVFM, notImplemented,    outOfDiskSpace, outOfVM, unableToFreeResidentHeapNode,    unexpectedHardwareError, unexpectedVolTableError};    goodCompletion: DiskChannel.IOStatus = [disk[goodCompletion]];    -------------------------------------------------------------------------------  -- AddToErrorList  -------------------------------------------------------------------------------       AddToErrorList: PUBLIC PROCEDURE [     file: File.ID, which: ET.WhichETableFile, problem: VI.ETableErrorType,      filePage: File.PageNumber] =         -- Adds the specified error to the errorList      BEGIN    IF VI.numberOfErrorsInErrorList = VI.maximumNumberOfErrorsInErrorList THEN {       VI.errorListOverflowed ¬ TRUE;       RETURN};    VI.errorList[VI.numberOfErrorsInErrorList] ¬       [file:file, which:which, problem:problem, filePage:filePage];    VI.numberOfErrorsInErrorList ¬ VI.numberOfErrorsInErrorList + 1;    END; --AddToErrorList--  CompactOverflow:  PUBLIC PROCEDURE [      lvbi: LONG POINTER TO ETable.LVBucketInfo, firstFree: LONG CARDINAL] =             BEGIN            -- STEP 18  moves all the true ETable's in the overflow to the beginning       -- of the overflow area, squeezing out the space occupied by deleted       -- ETables.  The space freed up can then be reused.                  -- Only the destination block is ever written.  If the computer should fail      -- in the middle of processing, we would only be left with duplicated       -- entries.  Previous Verifier steps would then handle this case the next       -- time the volume is opened.  Since an overflow      -- block is several pages, preimaging must be used to guarantee completion       -- of an initiated write operation.            destination: File.PageNumber;      destinationHandle: ET.BucketHandle;      offsetInDestination: LONG CARDINAL;      currentETableInDestination: ET.ETableHandle;      source: File.PageNumber;      sourceHandle: ET.BucketHandle;      offsetInSource: LONG CARDINAL;      currentETableInSource: ET.ETableHandle;      size: CARDINAL;      blockSize: CARDINAL ¬ ETI.overflowBufferSize * Environment.wordsPerPage;            -- Internal procedures used in STEP 18.            CompactDestination: PROCEDURE [] =                -- Moves the real ETables in the current destination block to the 	 -- beginning of that block.  Uses and modifies the following parameters	 -- (global to STEP 18): currentETableInDestination, offsetInDestination.	           BEGIN	 sourcePointer: ET.ETableHandle ¬	    currentETableInDestination;	 tempOffsetInSource: LONG CARDINAL ¬ offsetInDestination;	 size: CARDINAL;	 	 DO	 	    -- Continue loop if more ETables in block, otherwise EXIT.	 	    IF sourcePointer = LOOPHOLE[	       destinationHandle + blockSize, ET.ETableHandle] OR	       tempOffsetInSource = firstFree THEN EXIT;                  -- If a true ETable is present, move it toward the start of the block.	             IF sourcePointer.header.fileID ~= File.nullID THEN	       BEGIN	       size ¬ GetETableSize[sourcePointer];	       Inline.LongCOPY[	          from: sourcePointer,	          nwords: size,	          to: currentETableInDestination];	       currentETableInDestination ¬ currentETableInDestination + size;	       offsetInDestination ¬ offsetInDestination + size; -- Global.	       END 	    ELSE	       size ¬ sourcePointer.header.length;	    	    	    sourcePointer ¬ sourcePointer + size;	    tempOffsetInSource ¬ tempOffsetInSource + size;            ENDLOOP;	    	 -- If there is still room left in the block, create a hole.	    	 IF currentETableInDestination ~= LOOPHOLE[	    destinationHandle + blockSize, ET.ETableHandle] AND 	    offsetInDestination ~= firstFree THEN	    BEGIN	    currentETableInDestination.header.fileID ¬ File.nullID;	    currentETableInDestination.header.length ¬ MIN[	      CARDINAL[((destination + ETI.overflowBufferSize - 	      lvbi.firstOverflowPage) * Environment.wordsPerPage) - 	      offsetInDestination], CARDINAL[firstFree - offsetInDestination]];	    END;	 END;	       LogDestination: PROCEDURE [] =         BEGIN	 	 -- Write the destination overflow block out to the preimage logs.	 	 memPage: Environment.PageNumber ¬	    Space.PageFromLongPointer[destinationHandle];	 primaryVolumePage: Volume.PageNumber;	 	 copyVolumePage: Volume.PageNumber;	 FOR i: CARDINAL IN [0..ETI.overflowBufferSize) DO	    primaryVolumePage ¬ 	    ETI.WhereIsFilePageOnVolume[i + 1, lvbi.primaryETableHandle].volumePage;	    copyVolumePage ¬ 	       ETI.WhereIsFilePageOnVolume[i + 1, lvbi.copyETableHandle].volumePage;	    IF VI.WritePage[primaryVolumePage, memPage, VI.diskChannel,	       VI.firstPVPageOfLV]	       ~= goodCompletion THEN Bug[unexpectedHardwareError];	    IF VI.WritePage[copyVolumePage, memPage, VI.diskChannel,	       VI.firstPVPageOfLV]	       ~= goodCompletion THEN Bug[unexpectedHardwareError];	    memPage ¬ memPage + 1;	    ENDLOOP;	 lvbi.fileHandle.numberOfPagesLogged ¬ ETI.overflowBufferSize;	 lvbi.fileHandle.itemLogged ¬ overflowBucket;	 lvbi.fileHandle.firstFilePageLogged ¬ destination;	 IF VI.WritePage[ETI.WhereIsFilePageOnVolume[	    0, lvbi.copyETableHandle].volumePage,	    Space.PageFromLongPointer[lvbi.fileHandle], VI.diskChannel,	    VI.firstPVPageOfLV]	    ~= goodCompletion THEN Bug[unexpectedHardwareError];	 lvbi.fileHandle.numberOfPagesLogged ¬ ETI.overflowBufferSize;	 lvbi.fileHandle.itemLogged ¬ overflowBucket;	 lvbi.fileHandle.firstFilePageLogged ¬ destination;	 IF VI.WritePage[	    ETI.WhereIsFilePageOnVolume[0, lvbi.primaryETableHandle].volumePage,	    Space.PageFromLongPointer[lvbi.fileHandle], VI.diskChannel,	    VI.firstPVPageOfLV]	    ~= goodCompletion THEN Bug[unexpectedHardwareError];	 END;	       ScratchLog: PROCEDURE [] =         	 -- Set the preimage logs to empty.	          BEGIN	 lvbi.fileHandle.numberOfPagesLogged ¬ 0;	 lvbi.fileHandle.itemLogged ¬ nothingLogged;	 IF VI.WritePage[ETI.WhereIsFilePageOnVolume[	    0, lvbi.copyETableHandle].volumePage,	    Space.PageFromLongPointer[lvbi.fileHandle], VI.diskChannel,	    VI.firstPVPageOfLV]	    ~= goodCompletion THEN Bug[unexpectedHardwareError];	 lvbi.fileHandle.numberOfPagesLogged ¬ 0;	 lvbi.fileHandle.itemLogged ¬ nothingLogged;	 IF VI.WritePage[ETI.WhereIsFilePageOnVolume[	    0, lvbi.primaryETableHandle].volumePage,	    Space.PageFromLongPointer[lvbi.fileHandle], VI.diskChannel,	    VI.firstPVPageOfLV]	    ~= goodCompletion THEN Bug[unexpectedHardwareError];	 END;	             -- Mainline code for compacting the overflow.            -- Notice that offsetInDestination and currentETableInDestination      -- always point to the first word after the compacted part of the       -- overflow.                  BEGIN       -- Allocate real memory for the source and destination.            destinationHandle ¬	 LOOPHOLE[Space.Allocate[ETI.overflowBufferSize	 ! Space.InsufficientSpace => Bug[outOfVM]].pointer];      VM.ScratchMap[[Space.PageFromLongPointer[destinationHandle], 	 ETI.overflowBufferSize]];      sourceHandle ¬	 LOOPHOLE[Space.Allocate[ETI.overflowBufferSize	 ! Space.InsufficientSpace => Bug[outOfVM]].pointer];      VM.ScratchMap[[Space.PageFromLongPointer[sourceHandle], 	 ETI.overflowBufferSize]];                  -- Read in the destination (first overflow block) and source       -- (last overflow block).  May be same blocks.      -- Reestablish firstFree.            destination ¬ lvbi.firstOverflowPage;      ReadInPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,         Space.PageFromLongPointer[destinationHandle]];      firstFree ¬ LOOPHOLE[destinationHandle.header.freeSpace];      source ¬ lvbi.firstOverflowPage +          (firstFree / (Environment.wordsPerPage * ETI.overflowBufferSize)) *	 ETI.overflowBufferSize;      ReadInPageRun[ETI.overflowBufferSize, source, lvbi.copyETableHandle,         Space.PageFromLongPointer[sourceHandle]];	       -- Set up compaction loop parameters           offsetInDestination ¬ SIZE[ET.FreeSpaceInOverflow];      currentETableInDestination ¬ @destinationHandle.eTables[0];      IF destination = source THEN          BEGIN	 offsetInSource ¬ SIZE[ET.FreeSpaceInOverflow];         currentETableInSource ¬ @sourceHandle.eTables[0];	 END      ELSE          BEGIN          offsetInSource ¬ (source - lvbi.firstOverflowPage) *             Environment.wordsPerPage;          currentETableInSource ¬ LOOPHOLE[sourceHandle, ET.ETableHandle];	  END;            -- Compact the destination block.  If destination = source, done.            CompactDestination[];      IF destination = source THEN         BEGIN	 LogDestination[];	 WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,	    Space.PageFromLongPointer[destinationHandle]];	 WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.primaryETableHandle,	    Space.PageFromLongPointer[destinationHandle]];	 ScratchLog[];	 GOTO exit;	 END;          -- We know that there are at least two blocks in the overflow, so      -- source and destination are distinct blocks.          DO             -- If there are no more ETables in source,  form preimage log of          -- destination, write out the destination, and scratch         -- the preimage log.  Move to previous block for source.  If        -- this is the destination, EXIT, we are done.             IF LOOPHOLE[currentETableInSource, LONG CARDINAL] = 	   LOOPHOLE[sourceHandle + blockSize, LONG CARDINAL] OR            offsetInSource = firstFree THEN 	   	   -- No more ETables in source.	   	   BEGIN	   IF LOOPHOLE[currentETableInDestination, LONG CARDINAL] ~= 	      LOOPHOLE[destinationHandle, LONG CARDINAL] + blockSize THEN 	      BEGIN	      	      -- A hole must be set up in destination.  Notice the assumption 	      -- that there is indeed an additional block and that therefore 	      -- firstFree does not point to this block.	      	      currentETableInDestination.header.fileID ¬ File.nullID;	      currentETableInDestination.header.length ¬ CARDINAL[	         ((destination + ETI.overflowBufferSize - lvbi.firstOverflowPage) *	         Environment.wordsPerPage) - offsetInDestination];	      END;	   LogDestination[];	   WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,	      Space.PageFromLongPointer[destinationHandle]];	   WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.primaryETableHandle,	      Space.PageFromLongPointer[destinationHandle]];	   ScratchLog[];	   source ¬ source - ETI.overflowBufferSize;	   IF source = destination THEN EXIT;	   ReadInPageRun[ETI.overflowBufferSize, source, lvbi.copyETableHandle,	      Space.PageFromLongPointer[sourceHandle]];	   offsetInSource ¬ (source - lvbi.firstOverflowPage) * 	      Environment.wordsPerPage;           currentETableInSource ¬ LOOPHOLE[sourceHandle, ET.ETableHandle];	   END;		-- Now have some type of source entry.  Skip the source entry if a hole        -- (nul FileID) rather than a real ETable.  Notice that we cannot 	-- be at the end of the overflow.             IF currentETableInSource.header.fileID = File.nullID THEN           BEGIN	   offsetInSource ¬ offsetInSource + currentETableInSource.header.length;           currentETableInSource ¬ currentETableInSource +	      currentETableInSource.header.length;	   LOOP;           END;               -- Now have a true ETable as the source entry.		size ¬ GetETableSize[currentETableInSource];        	-- The destination will accommodate the ETable if either there 	-- is enough room for the ETable plus an addition header (to	-- accommodate a hole at the end, if necessary), or the ETable fits 	-- exactly.	IF LOOPHOLE[currentETableInDestination, LONG CARDINAL] + 	   size + SIZE[ET.ETableHeader] <= 	   LOOPHOLE[destinationHandle, LONG CARDINAL] + blockSize OR 	   LOOPHOLE[currentETableInDestination, LONG CARDINAL] + size = 	   LOOPHOLE[destinationHandle, LONG CARDINAL] + blockSize THEN 	   BEGIN	   	   -- Destination can accommodate the ETable.	   -- Move ETable from source to destination.		   Inline.LongCOPY[	      from: currentETableInSource, 	      nwords: size,	      to: currentETableInDestination];	   currentETableInSource ¬ currentETableInSource + size;	   offsetInSource ¬ offsetInSource + size;	   currentETableInDestination ¬ currentETableInDestination + size;	   offsetInDestination ¬ offsetInDestination + size;	   LOOP;	   END;	           -- Destination cannot accommodate the ETable.  Form preimage        -- log of destination, write out the destination, and scratch         -- the preimage log. Read in the next block (one will always exist,         -- otherwise there was no source).  Compact it.  If same as source,         -- form preimage log of destination, write out destination/source,         -- scratch the preimage log, and EXIT, we are done.	           -- Unless the destination block is full, create a hole for         -- the remainder of the block.	           IF LOOPHOLE[currentETableInDestination, LONG CARDINAL] ~= 	   LOOPHOLE[destinationHandle, LONG CARDINAL] + blockSize THEN 	   BEGIN	      	   -- A hole must be set up in destination.	      	   currentETableInDestination.header.fileID ¬ File.nullID;	   currentETableInDestination.header.length ¬ CARDINAL[	      ((destination + ETI.overflowBufferSize - lvbi.firstOverflowPage) *	      Environment.wordsPerPage) - offsetInDestination];	   END;        LogDestination[];        WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,	   Space.PageFromLongPointer[destinationHandle]];        WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.primaryETableHandle,	   Space.PageFromLongPointer[destinationHandle]];        ScratchLog[];	           -- Move to next destination block.	           destination ¬ destination + ETI.overflowBufferSize;        offsetInDestination ¬ (destination - lvbi.firstOverflowPage) *	   Environment.wordsPerPage;        currentETableInDestination ¬ LOOPHOLE[	   destinationHandle, ET.ETableHandle];        ReadInPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,	   Space.PageFromLongPointer[destinationHandle]];        IF destination = source THEN 	   BEGIN	      	   -- Destination made same as partially processed source.	      	   tempETableHandle: ETable.ETableHandle ¬ LOOPHOLE[	      destinationHandle, ET.ETableHandle];	      	   -- If some of the source entries have been processed, convert 	   -- them into a hole.  Never want to see these again.	      	   IF currentETableInSource ~= LOOPHOLE[sourceHandle, ET.ETableHandle] THEN 	      BEGIN	      tempETableHandle.header.fileID ¬ File.nullID;	      tempETableHandle.header.length ¬ CARDINAL[offsetInSource - 	         (source - lvbi.firstOverflowPage) * Environment.wordsPerPage];	      END;	   END;        CompactDestination[];        IF destination = source THEN 	   BEGIN	   LogDestination[];	   WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.copyETableHandle,	      Space.PageFromLongPointer[destinationHandle]];	   WriteOutPageRun[ETI.overflowBufferSize, destination, lvbi.primaryETableHandle,	      Space.PageFromLongPointer[destinationHandle]];	   ScratchLog[];	   EXIT;	   END;        ENDLOOP;	EXITS	   exit => NULL;	END;	       -- Update the overflow next free pointer (one page so atomic).            [] ¬ VI.ReadPage         [ETI.WhereIsFilePageOnVolume[	 lvbi.firstOverflowPage, lvbi.copyETableHandle].volumePage, 	 Space.PageFromLongPointer[destinationHandle],	 VI.diskChannel, VI.firstPVPageOfLV];      destinationHandle.header.freeSpace ¬ LOOPHOLE[offsetInDestination];      [] ¬ VI.WritePage         [ETI.WhereIsFilePageOnVolume[	    lvbi.firstOverflowPage, lvbi.copyETableHandle].volumePage, 	 Space.PageFromLongPointer[destinationHandle],	 VI.diskChannel, VI.firstPVPageOfLV];      [] ¬ VI.WritePage         [ETI.WhereIsFilePageOnVolume[	    lvbi.firstOverflowPage, lvbi.primaryETableHandle].volumePage, 	 Space.PageFromLongPointer[destinationHandle],	 VI.diskChannel, VI.firstPVPageOfLV];            -- Release the memory            VM.Unmap[Space.PageFromLongPointer[destinationHandle]];      Space.Deallocate[[destinationHandle, ETI.overflowBufferSize]];      VM.Unmap[Space.PageFromLongPointer[sourceHandle]];      Space.Deallocate[[sourceHandle, ETI.overflowBufferSize]];      END; -- CompactDestination--          -------------------------------------------------------------------------------  -- CompactFilesInOverflow    -------------------------------------------------------------------------------    -- This procedure is called by VerifierAccessProc (STEP 19) when a compaction   -- has been requested (by Othello or the Installer). At this point a complete   -- scavenge has been performed.      CompactFilesInOverflow: PUBLIC PROCEDURE [     lvbi: LONG POINTER TO ET.LVBucketInfo, lvHandle: LogicalVolumeFormat.Handle,      token: VolTable.LVToken] =     BEGIN     offsetInOverflow: LONG CARDINAL;     blockSize: CARDINAL ¬ ETI.overflowBufferSize * Environment.wordsPerPage;     currentETable: ET.ETableHandle;     firstFree: LONG CARDINAL;     memPage: Environment.PageNumber;     memPagePtr: LONG POINTER TO ARRAY[0..0) OF CARDINAL;     NewETableType: TYPE = RECORD[header: ET.ETableHeader,        pageGroups: ARRAY[0..ETI.maxPageGroupSize) OF ET.PageGroup];     NewETable: NewETableType;     newETable: LONG POINTER TO NewETableType ¬ @NewETable;     status: disk DiskChannel.IOStatus;     i, j: CARDINAL;     initialSize--, remaining--: File.PageCount;     filePage: File.PageNumber;           -- Set up loop on ETables in overflow          memPagePtr ¬        LOOPHOLE[Space.Allocate[1 ! Space.InsufficientSpace => Bug[outOfVM]].pointer];     memPage ¬ Space.PageFromLongPointer[memPagePtr];     VM.ScratchMap[[memPage, 1]];     ReadInPageRun[        ETI.overflowBufferSize, lvbi.firstOverflowPage, lvbi.primaryETableHandle,	Space.PageFromLongPointer[lvbi.overflowHandle]];     lvbi.currentOverflowPage ¬ lvbi.firstOverflowPage;     lvbi.freeSpaceInOverflow ¬         lvbi.overflowHandle.header.freeSpace;     firstFree ¬ LOOPHOLE[lvbi.overflowHandle.header.freeSpace];     offsetInOverflow ¬ SIZE[ET.FreeSpaceInOverflow];     currentETable ¬ @lvbi.overflowHandle.eTables[0];                -- Examine each ETable in overflow and try to compact the corresponding file.           UNTIL offsetInOverflow = firstFree DO         IF currentETable.header.fileID ~= File.nullID AND 	   currentETable.header.bootable = FALSE THEN	   BEGIN	   	   -- We have found an ETable 	   	   fileD: KernelFile.Descriptor ¬ [              fileID: currentETable.header.fileID, volumeID: lvHandle.vID, 	      temporary: FALSE, size: 0, type: currentETable.header.type];	   group: KernelFile.PageGroup;	   	   -- Set up new (currently largely empty) ETable.	   	   newETable.header ¬ currentETable.header;	   newETable.header.howManyGroups ¬ 0;	   j ¬ 0;	   	   -- Populate new ETable with page groups.  	    	   -- NOTE: Might at some time wish to skip this if 	   -- currentETable.pageGroups[i].count is small.	   	   initialSize ¬ 0;	   FOR i IN [0..currentETable.header.howManyGroups) DO	      initialSize ¬ initialSize + currentETable.pageGroups[i].count;	      ENDLOOP;	   group ¬ [              filePage: 0,              volumePage: 0,              nextFilePage: MIN[initialSize, LAST[CARDINAL]]];	   UNTIL fileD.size = initialSize DO	      BEGIN	      ENABLE ANY => Bug[fileSystemError];	      IF newETable.header.howManyGroups = ETI.maxPageGroupSize THEN GO TO Undo;              VolAllocMap.AllocPageGroup[                 vol: lvHandle, filePtr: @fileD, groupPtr: @group,                 data: VM.nullInterval, tok: token !                 Volume.InsufficientSpace => GO TO Undo];	         -- results in modified group and FilePtr.size              newETable.header.howManyGroups ¬ newETable.header.howManyGroups + 1;	      j ¬ j + 1;	      newETable.pageGroups[j - 1] ¬	         [count: CARDINAL[group.nextFilePage - group.filePage], 		 volumePage: group.volumePage];	     -- remaining ¬ initialSize - fileD.size;	      group ¬ [	         filePage: fileD.size,	         volumePage: newETable.pageGroups[j - 1].volumePage + 		    newETable.pageGroups[j - 1].count,	         nextFilePage: MIN[initialSize, LAST[CARDINAL]]];	      END; --ENABLE	      REPEAT                 Undo => {	            filePage: File.PageNumber ¬ 0;	            FOR i: CARDINAL IN [0..j) DO	               group ¬ [filePage, newETable.pageGroups[i].volumePage,	                 filePage + newETable.pageGroups[i].count];                       VolAllocMap.FreePageGroup[	                 vol: lvHandle, filePtr: @fileD, groupPtr: @group, tok: token];	               filePage ¬ filePage + newETable.pageGroups[i].count;                       ENDLOOP;		    GO TO moveToNextETable};              ENDLOOP; --Populate new ETable with page groups--	   	   -- Copy over the file data.	   	   -- Notice that a failure anywhere within this loop is benign.  On the 	   -- next boot the Scavenger will deallocate all these pages.	   	   -- If there is a need, performance could be improved by reading and	   -- writing in larger units.	   	   FOR i: Volume.PageCount IN [0..fileD.size) DO	      status ¬ VI.ReadPage[	         ETI.WhereIsFilePageOnVolume[i, currentETable].volumePage, 		 memPage, VI.diskChannel, VI.firstPVPageOfLV];	      IF status ~= goodCompletion THEN Bug[unexpectedHardwareError];	      status ¬ VI.WritePage[	         ETI.WhereIsFilePageOnVolume[		    i, LOOPHOLE[newETable, ET.ETableHandle]].volumePage, 		 memPage, VI.diskChannel, VI.firstPVPageOfLV];	      IF status ~= goodCompletion THEN Bug[unexpectedHardwareError];	      ENDLOOP;	   	   -- Deallocate the pages of the old file.	   	   -- Notice that a failure with this loop is benign.  On the next boot 	   -- the Scavenger will reallocate these pages since they are claimed	   -- by the old file's ETable. 	   	   filePage ¬ 0;	   FOR i: CARDINAL IN [0..currentETable.header.howManyGroups) DO	      group ¬ [filePage, currentETable.pageGroups[i].volumePage,	         filePage + currentETable.pageGroups[i].count];              VolAllocMap.FreePageGroup[	         vol: lvHandle, filePtr: @fileD, groupPtr: @group, tok: token];	      filePage ¬ filePage + currentETable.pageGroups[i].count;              ENDLOOP;	   	   -- Replace the old ETable with the new.	   	   lvbi.currentBucketPage ¬ lvbi.firstBucketPage +	      CARDINAL[LOOPHOLE[currentETable.header.fileID, LONG UNSPECIFIED] MOD	      lvbi.hash];	   status ¬ VI.ReadPage[	         ETI.WhereIsFilePageOnVolume[		 lvbi.currentBucketPage, lvbi.primaryETableHandle].volumePage, 		 Space.PageFromLongPointer[lvbi.bucketHandle], 		 VI.diskChannel,		 VI.firstPVPageOfLV];	   IF status ~= goodCompletion THEN Bug[unexpectedHardwareError];	   lvbi.fileID ¬ currentETable.header.fileID;     	   lvbi.eTableHandle ¬ currentETable;	   lvbi.inBucket ¬ FALSE;	   ETI.ReplaceOldETableInternal[	      lvbi­,	      LOOPHOLE[newETable,ET.ETableHandle]];	      	   EXITS	      moveToNextETable=> NULL;	   END; --Have found an ETable-- 	         -- Move to next ETable.	         IF currentETable.header.fileID ~= File.nullID THEN 	   BEGIN	   offsetInOverflow ¬ offsetInOverflow + GetETableSize[currentETable];	   currentETable ¬ currentETable + GetETableSize[currentETable];	   END        ELSE	   BEGIN	   offsetInOverflow ¬ offsetInOverflow + currentETable.header.length;	   currentETable ¬ currentETable + currentETable.header.length;	   END;	         -- Continue loop if more ETables in block.	         IF ~(currentETable = LOOPHOLE[lvbi.overflowHandle + blockSize, ET.ETableHandle] 	   OR offsetInOverflow = firstFree) THEN LOOP;	         -- Finished if at end of overflow, else read in next block and loop.	 	IF offsetInOverflow = firstFree THEN EXIT;        currentETable ¬ LOOPHOLE[lvbi.overflowHandle]; --for non-first block        lvbi.currentOverflowPage ¬ 	   lvbi.currentOverflowPage + ETableInternal.overflowBufferSize;	ReadInPageRun[        ETI.overflowBufferSize, lvbi.currentOverflowPage, lvbi.primaryETableHandle,	Space.PageFromLongPointer[lvbi.overflowHandle]];        ENDLOOP; -- Examine each ETable in overflow--     VM.Unmap[memPage];     Space.Deallocate[[memPagePtr, 1]];     END; --CompaceFilesInOverflow--    -------------------------------------------------------------------------------  -- FileIDFromNumber  -------------------------------------------------------------------------------    FileIDFromNumber: PROC [id: FileInternal.FileID] RETURNS [File.ID] = INLINE {    RETURN[LOOPHOLE[id]]};   -------------------------------------------------------------------------------  -- GetETableSize  -------------------------------------------------------------------------------    GetETableSize: PROCEDURE [eTable: ET.ETableHandle] RETURNS [CARDINAL] =     INLINE {  RETURN[CARDINAL[     SIZE[ET.ETableHeader] +      (SIZE[ET.PageGroup] * eTable.header.howManyGroups)]] };   ---------------------------------------------------------------------------  -- ProduceScavengerLog   ---------------------------------------------------------------------------    ProduceScavengerLog: PUBLIC PROCEDURE [     lvHandle: LVF.Handle,      lvToken: VolTable.LVToken,      globalForLogFile: File.File,      lvbi: ET.LVBucketInfo]   RETURNS[File.File] =         BEGIN         	       logInfo: VI.LogInfo;      fileEntry: Scavenger.FileEntry;      fileID: File.ID ¬ File.nullID;      filePage: File.PageNumber;      bufferSpace: Space.Interval;      logBufferSize: Environment.PageCount ¬ 1;      headerPointer: LONG POINTER TO Scavenger.Header;      justCreated: BOOLEAN;      CreateScavengerLogFile: PROCEDURE [] =         BEGIN	 initialSize: CARDINAL = 30;	 -- This must be >= the following equation: initialSize ¬	 -- (VI.maximumNumberOfErrorsInErrorList * (SIZE[Scavenger.FileEntry] +	 -- SIZE[File.PageNumber]) + SIZE[Scavenger.Header])/	 -- Environment.wordsPerPage + 1;         fileD: KernelFile.Descriptor ¬ [            fileID: globalForLogFile.fileID, 	    volumeID: globalForLogFile.volumeID,	    temporary: FALSE, size: 0,            type: PilotFileTypes.tScavengerLog];         group: KernelFile.PageGroup;         prevGroup: KernelFile.PageGroup ¬ [            filePage: 0, volumePage: 0, nextFilePage: 0];         countPageGroups: CARDINAL ¬ 0;	 initialPageGroups: ARRAY [0..initialSize) OF ETable.PageGroup;         pageGroups: ETable.PageGroupHandle ¬ DESCRIPTOR[initialPageGroups];         IF lvHandle.freePageCount < initialSize            THEN ERROR Volume.InsufficientSpace[	       lvHandle.freePageCount, globalForLogFile.volumeID];         -- Must get all page groups at once and pass to ETable software         UNTIL (fileD.size = initialSize) DO            group ¬ [               filePage: prevGroup.nextFilePage,               volumePage: prevGroup.volumePage +	       (prevGroup.nextFilePage - prevGroup.filePage),               nextFilePage: initialSize];            VolAllocMap.AllocPageGroup[               vol: lvHandle, filePtr: @fileD, groupPtr: @group,               data: VM.nullInterval, tok: lvToken !               Volume.InsufficientSpace => ERROR Scavenger.Error[cannotWriteLog]];	       -- Results in modified group and FilePtr.size.            pageGroups[countPageGroups] ¬               [count: CARDINAL[group.nextFilePage - group.filePage], 	       volumePage: group.volumePage];            countPageGroups ¬ countPageGroups + 1;            prevGroup ¬ group;            ENDLOOP;         pageGroups.LENGTH ¬ countPageGroups;         [] ¬ ETI.CreateETableInternal[	    lvbi, fileD.fileID, pageGroups, PilotFileTypes.tScavengerLog !            Volume.InsufficientSpace =>                ERROR Volume.InsufficientSpace[	       lvHandle.freePageCount, globalForLogFile.volumeID]];         END;  --CreateScavengerLog--            GetBSData: PROCEDURE [         file: File.File, filePage: File.PageNumber, type: File.Type,         temporary: BOOLEAN, lvHandle: LVF.Handle, lvToken: VolTable.LVToken]      RETURNS [bsData: BackingStore.Run] =         BEGIN         group: KernelFile.PageGroup;         success: BOOLEAN;         diskBSData: DiskBackingStore.Data;         filePageLow: DiskBackingStore.FilePageLow;         filePageHigh: DiskBackingStore.FilePageHigh;         channel: DiskBackingStore.ChannelHandle;         countValid: Volume.PageCount;         pvPage: PhysicalVolume.PageNumber;	 [success, group] ¬ 	    ETI.GetPageGroupInternal[	    lvBucketInfo: lvbi, token: lvToken, fileID: file.fileID, filePage: filePage];         IF ~success THEN Bug[neededFileNotInVFM];         [filePageLow, filePageHigh] ¬ DiskBackingStore.UnpackFilePageNumber[filePage];         [channel:channel, diskPage:pvPage, countValid:countValid] ¬ VI.GetDiskIOInfo[           file.volumeID, group.volumePage + (filePage - group.filePage), 1];         IF countValid < 1 THEN Bug[badInfoFromVFM];	 diskBSData ¬ [	   type: type, filePageLow: filePageLow,	   filePageHigh: filePageHigh,	   fileAttributes: [temporary: temporary, readOnly: FALSE],	   channelHandle: channel, volumePage: pvPage,	   placeHolder: TRASH];	 WITH d: diskBSData SELECT FileLock.lockingEnabled FROM	   TRUE => d.lock ¬ FileLock.nullLockHandle;	   FALSE => d.file ¬ File.nullID;	   ENDCASE;         RETURN[[1, DiskBackingStore.BSDataFromDiskData[diskBSData]]];         END;  --GetBSData--      	       OpenLogFile: PUBLIC PROCEDURE [         logInfo: LONG POINTER TO VI.LogInfo, lvHandle: LVF.Handle,         lvToken: VolTable.LVToken] =         BEGIN OPEN li: logInfo;         runs: ARRAY [0..1) OF BackingStore.Run;         runs[0] ¬            IF li.canUseFileOps THEN SpecialFile.GetBackingStoreRun[            [li.logFile, li.logVolume], li.firstLogPage, li.logType].run            ELSE GetBSData[	       [li.logFile, li.logVolume], li.firstLogPage, li.logType, FALSE,	        lvHandle, lvToken];         VM.Map[            interval: [li.logPage, 1], transferProc: DiskBackingStore.Transfer,            backingStoreRuns: DESCRIPTOR[runs], swapUnits: [unitary[]]];         li.currentLogPage ¬ li.firstLogPage;         li.nextWord ¬ 0;         END;  --OpenLogFile--	       CloseLogFile: PROCEDURE [] = INLINE {VM.Unmap[logInfo.logPage]};      	       PutWords: PUBLIC PROCEDURE [         logInfo: LONG POINTER TO VI.LogInfo, words: LONG POINTER, count: CARDINAL,         lvHandle: LogicalVolumeFormat.Handle, lvToken: VolTable.LVToken] =         BEGIN OPEN li: logInfo;         -- "stream" interface to ScavengeLog.         THROUGH [0..count) DO            IF li.nextWord >= Environment.wordsPerPage THEN	       BEGIN	       runs: ARRAY [0..1) OF BackingStore.Run;	       VM.Unmap[li.logPage];	       li.currentLogPage ¬ li.currentLogPage + 1;	       	       -- Catch end of log condition and go to noRoom.  !!!	       	      runs[0] ¬	         IF li.canUseFileOps THEN SpecialFile.GetBackingStoreRun[	            [li.logFile, li.logVolume], li.currentLogPage, li.logType].run	         ELSE GetBSData[	            [li.logFile, li.logVolume], li.currentLogPage, li.logType, 		    FALSE, lvHandle, lvToken];	      VM.Map[	         interval: [li.logPage, 1], transferProc: DiskBackingStore.Transfer,	         backingStoreRuns: DESCRIPTOR[runs], swapUnits: [unitary[]]];	      li.nextWord ¬ 0;	      END;            LOOPHOLE[li.logBuffer.pointer + li.nextWord, LONG POINTER TO WORD]­ ¬	       words­;            li.nextWord ¬ li.nextWord + 1;            words ¬ words + 1;            ENDLOOP;         END;  --PutWords--            -- Begin main processing in creation of client scavenger log.            -- Initialize the log.            justCreated ¬ FALSE;      IF globalForLogFile = File.nullFile THEN         BEGIN	 globalForLogFile.fileID ¬ FileIDFromNumber[PilotFileTypes.tScavengerLog];	 globalForLogFile.volumeID ¬ lvHandle.vID;	 IF ~VI.localScavengerLogFileExists THEN	    BEGIN	    CreateScavengerLogFile[];	    justCreated ¬ TRUE;	    END;	 lvHandle.scavengerLogVolume ¬ lvHandle.vID;	 END;      logInfo.logHeader ¬ [         seal: Scavenger.LogSeal,	 version: Scavenger.currentLogVersion,          volume: lvHandle.vID, date: System.GetGreenwichMeanTime[],          repairMode: riskyRepair,         incomplete: TRUE, repaired: TRUE,          numberOfFiles: VI.numberOfFiles,         bootFilesDeleted: Scavenger.noneDeleted,	 logEntries: 0];      logInfo.logFile ¬ globalForLogFile.fileID;      logInfo.logVolume ¬ globalForLogFile.volumeID;      logInfo.canUseFileOps ¬ (logInfo.logVolume ~= lvHandle.vID);      logInfo.firstLogPage ¬ 0;      logInfo.logType ¬ PilotFileTypes.tScavengerLog;      logInfo.nextWord ¬ 0;      logInfo.currentLogPage ¬ 0;      logInfo.logFilePages ¬ 0;  -- Currently unused.      logInfo.logDone ¬ FALSE;      bufferSpace ¬ Space.Allocate[logBufferSize];      logInfo.logBuffer ¬ [bufferSpace.pointer, logBufferSize];      logInfo.logPage ¬ Space.PageFromLongPointer[logInfo.logBuffer.pointer];            OpenLogFile[@logInfo, lvHandle, lvToken];            -- If old log file is from current Pilot version and non-empty, done.      -- If there are client problems not in log, they will have to be fixed in      -- a latter scavenge.      -- If there is a badETableInBucket problem, get it reported to so the client      -- scavenger runs. Doesn't matter what fileID and page number are.            headerPointer ¬ LOOPHOLE[logInfo.logBuffer.pointer];      IF ~justCreated AND          headerPointer.seal = Scavenger.LogSeal AND          headerPointer.version = Scavenger.currentLogVersion AND 	 headerPointer.logEntries ~= 0 THEN	 BEGIN	 VI.skipClientPageCorrections ¬ TRUE;	 headerPointer.incomplete ¬ TRUE; 	 CloseLogFile[];	 Space.Deallocate[logInfo.logBuffer];         RETURN[globalForLogFile];	 END;       PutWords[  -- (reserves space for the header)         @logInfo, @logInfo.logHeader, SIZE[Scavenger.Header], lvHandle,         lvToken];      FOR i: CARDINAL IN [0..VI.numberOfErrorsInErrorList) DO	 IF VI.errorList[i].problem ~= badClientPage AND	    VI.errorList[i].problem ~= badClientData AND	    VI.errorList[i].problem ~= badETableInBucket THEN LOOP;	 IF (VI.errorList[i].file ~= fileID OR 	    VI.errorList[i].problem = badETableInBucket) THEN	    BEGIN	    fileID ¬ VI.errorList[i].file;	    logInfo.logHeader.logEntries ¬ logInfo.logHeader.logEntries + 1;	    fileEntry.file ¬ VI.errorList[i].file;	    fileEntry.numberOfProblems ¬ 0;	    FOR j: CARDINAL IN [i..VI.numberOfErrorsInErrorList) DO	       IF VI.errorList[j].file ~= fileID THEN EXIT;	       fileEntry.numberOfProblems ¬ fileEntry.numberOfProblems + 1;		       ENDLOOP;	    PutWords[@logInfo, @fileEntry, SIZE[Scavenger.FileEntry], 	       lvHandle, lvToken];	    END;	 filePage ¬ VI.errorList[i].filePage;	 PutWords[           @logInfo, @filePage, SIZE[File.PageNumber], lvHandle,           lvToken];	 ENDLOOP;      logInfo.logHeader.incomplete ¬         IF VI.errorListOverflowed THEN TRUE ELSE FALSE;      CloseLogFile[];      OpenLogFile[@logInfo, lvHandle, lvToken];      PutWords[        @logInfo, @logInfo.logHeader, SIZE[Scavenger.Header], lvHandle,        lvToken];      CloseLogFile[];      Space.Deallocate[logInfo.logBuffer];      RETURN[globalForLogFile]            END; --ProduceScavengerLog--          -------------------------------------------------------------------------------  -- ValidateAndRepairRootDirectory  -------------------------------------------------------------------------------    ValidateAndRepairRootDirectory: PUBLIC PROCEDURE [    lvbi: LONG POINTER TO ET.LVBucketInfo, vol: LVF.Handle,    token: VolTable.LVToken] =    BEGIN    rootDir: LONG POINTER TO LVF.RootDirectory ¬ NIL;  -- nonNIL means mapped.    rootDirPage: Environment.PageNumber;    lvID: Volume.ID = lvbi.lvHandle.vID;    BEGIN  --scope of MakeRootDirNull--    rootDirectory: File.ID = lvbi.lvHandle.volumeRootDirectory;    IF rootDirectory = File.nullID THEN RETURN;  -- vacuously correct!    ETI.FindETable[lvbi­, rootDirectory];    IF lvbi.eTableHandle = NIL THEN GO TO MakeRootDirNull;    IF lvbi.eTableHandle.header.type # PilotFileTypes.tRootDirectory OR      ETI.GetSize[lvbi.eTableHandle] # LVF.MaxPagesInRootDirectory THEN      BEGIN      ETI.DeleteETableInternal[lvbi­, rootDirectory];        -- note that the VAM pages remain busy here...but this won't hurt us	-- and they will be reclaimed next time we boot      GO TO MakeRootDirNull;      END;    rootDir ¬ Space.Allocate[LVF.MaxPagesInRootDirectory !      Space.InsufficientSpace => Bug[outOfVM]].pointer;    rootDirPage ¬ Space.PageFromLongPointer[rootDir];    VM.ScratchMap[[page: rootDirPage, count: LVF.MaxPagesInRootDirectory]];    ReadInPageRun[      CARDINAL[LVF.MaxPagesInRootDirectory], 0, lvbi.eTableHandle, rootDirPage];    -- Validate the root directory and fix it if necessary    -- At this point we know that the root directory is the right size and that    -- all of its pages are good pages (i.e., readable)    IF rootDir.seal ~= LVF.RootDirSeal OR rootDir.version ~= LVF.RootDirVersion      OR rootDir.maxEntries ~= LVF.MaxEntriesInRootDirectory      OR rootDir.countEntries > rootDir.maxEntries THEN      BEGIN  -- clean out the root directory and let the client rebuild it:      rootDir­ ¬ [entries: NULL];  -- everything else defaults correctly      FOR i: CARDINAL IN [0..rootDir.maxEntries) DO	rootDir.entries[i] ¬ [FileTypes.tUntypedFile, File.nullID];	ENDLOOP;      WriteOutPageRun[        CARDINAL[LVF.MaxPagesInRootDirectory], 0, lvbi.eTableHandle, rootDirPage];      END;    EXITS      MakeRootDirNull =>	BEGIN	subvolumes: LONG DESCRIPTOR FOR ARRAY OF ScavengerUtilities.SVInfo;	vol.volumeRootDirectory ¬ File.nullID;  -- actually set in root page	subvolumes ¬ ScavengerUtilities.GatherLVMarkerPages[token, lvID];	FOR subvolumeIndex: CARDINAL IN [0..LENGTH[subvolumes]) DO	  subvolumes[subvolumeIndex].marker.logical.volumeRootDirectory ¬	    File.nullID;	  ENDLOOP;	ScavengerUtilities.FreeLVMarkerPages[subvolumes !	  Space.Error => CONTINUE];	VM.ForceOut[	  [Space.PageFromLongPointer[lvbi.lvHandle], LVF.rootPageSize], wait];	RETURN;	END;    END;  --scope of MakeRootDirNull--    VM.Unmap[rootDirPage];    Space.Deallocate[[pointer: rootDir, count: LVF.MaxPagesInRootDirectory]];    END;  --ValidateAndRepairRootDirectory--                 -------------------------------------------------------------------------------  -- ReadInPageRun    -------------------------------------------------------------------------------    ReadInPageRun: PROCEDURE [     count: CARDINAL, filePageNumber: File.PageNumber, eTable: ET.ETableHandle,      memPageNumber: Environment.PageNumber] =     BEGIN	      -- Read into memory, beginning at page memPageNumber, the page run	      FOR i: CARDINAL IN [0..count) DO        IF VI.ReadPage[ETI.WhereIsFilePageOnVolume[	   i + filePageNumber, eTable].volumePage, memPageNumber, VI.diskChannel, 	   VI.firstPVPageOfLV]	   ~= goodCompletion THEN Bug[unexpectedHardwareError];        memPageNumber ¬ memPageNumber + 1;        ENDLOOP;     END; --ReadInPageRun--        -------------------------------------------------------------------------------  -- WriteOutPageRun    -------------------------------------------------------------------------------    WriteOutPageRun: PUBLIC PROCEDURE [    count: CARDINAL, filePageNumber: File.PageNumber, eTable: ET.ETableHandle,     memPageNumber: Environment.PageNumber] =    BEGIN	     -- Write out the page run which starts at memory page memPageNumber    -- to the position in the specified file.	     FOR i: CARDINAL IN [0..count) DO       IF VI.WritePage[ETI.WhereIsFilePageOnVolume[          i + filePageNumber, eTable].volumePage, memPageNumber, VI.diskChannel, 	   VI.firstPVPageOfLV]	   ~= goodCompletion THEN Bug[unexpectedHardwareError];       memPageNumber ¬ memPageNumber + 1;       ENDLOOP;    END; --WriteOutPageRun--      -------------------------------------------------------------------------------  -- MapMarkerPage and UnmapMarkerPage    -------------------------------------------------------------------------------    MapMarkerPage: PUBLIC PROCEDURE [volume: Volume.ID, tok: VolTable.LVToken]     RETURNS [svTok: VolTable.SVToken, markerSpace: Space.Interval] =    BEGIN    svDesc: VolTable.SVDesc;    markerSpace ¬ Space.Allocate[PVF.markerPageSize];    VolTable.GetNextSV[[byLV[volume, [first[]]]], @svDesc];    svTok ¬ VolTable.GetSVToken[tok, svDesc.lvPageOfSV];    VolTable.MapMarkerPage[svTok, markerSpace.pointer];    --lvmp ¬ @subvolume.marker.logical;    END;      UnmapMarkerPage: PUBLIC PROCEDURE [    svTok: VolTable.SVToken, markerSpace: Space.Interval] =    BEGIN    VolTable.UnmapMarkerPage[svTok, markerSpace.pointer];    Space.Deallocate[markerSpace];    END;        -------------------------------------------------------------------------------  --  FAST VERIFY CODE STARTS BELOW (ET)    -------------------------------------------------------------------------------  -- DoIOForOneRun and GatherRunsAndDoIO have been copied (slightly modified) from  -- ETableImplB$DoOverflowIO. ETableInternal should export them   -- instead of copying them here.  DoIOForOneRun: PUBLIC PROCEDURE [    memBuffer: LONG POINTER, volumePage: Volume.PageNumber,     diskChannel: DiskChannel.Handle, firstPVPageOfLV: PhysicalVolume.PageNumber,     countRequested: CARDINAL, io: VI.IOType]    RETURNS [upDatedBuffer: LONG POINTER, dataError: BOOLEAN ¬ FALSE] =     -- Read the specified pages into resident memory.    -- It is assumed that diskChannel has already been initialized.    -- Will not work if LV's can span PV's.    BEGIN    ioStatus: DiskChannel.IOStatus;    request: DiskChannel.IORequest;    countValid: LONG CARDINAL;    countDone: CARDINAL ¬ 0;    upDatedBuffer ¬ memBuffer;    WHILE (countDone # countRequested) DO      request ¬ [	diskPage: firstPVPageOfLV + volumePage + countDone,	memoryPage: Environment.PageFromLongPointer[upDatedBuffer],	count: countRequested - countDone,	command: IF io = read THEN read ELSE write,        tries: DiskChannel.defaultTries, useSamePage: FALSE];      [ioStatus, countValid] ¬ DiskChannel.DoIO[diskChannel, @request];      WITH diskStatus: ioStatus SELECT FROM	 invalidChannel => Bug[invalidChannel];	 invalidDriveState => Bug[invalidDriveState];	 disk => 	   IF diskStatus.status # goodCompletion THEN {	     dataError ¬ TRUE;	     -- zero out data and continue. 	     LOOPHOLE[upDatedBuffer,	       LONG POINTER TO ARRAY[0..Environment.wordsPerPage] OF CARDINAL]­ ¬		 ALL[0];	     countDone ¬ countDone + 1};	 ENDCASE => Bug[impossibleEndcase];      countDone ¬ countDone + CARDINAL[countValid];      upDatedBuffer ¬ memBuffer + countDone*Environment.wordsPerPage;      ENDLOOP;    END; --DoIOForOneRun--      GatherRunsAndDoIO: PUBLIC PROCEDURE [    eTable: ETable.ETableHandle, memBuffer: LONG POINTER,     bucketPage: File.PageNumber, countLeft: CARDINAL, io: VI.IOType]     RETURNS [dataError: BOOLEAN ¬ FALSE] =    BEGIN    error: BOOLEAN;    run: RECORD[volumePage: Volume.PageNumber, count: CARDINAL];    i: CARDINAL ¬ 0;    page: File.PageNumber ¬ bucketPage;    startPage: File.PageNumber ¬ 0;    UNTIL i = eTable.header.howManyGroups DO      IF page < startPage + eTable.pageGroups[i].count THEN {	offset: CARDINAL ¬ CARDINAL[page - startPage];	run.volumePage ¬ eTable.pageGroups[i].volumePage + offset;	run.count ¬ MIN[eTable.pageGroups[i].count - offset, countLeft];	[memBuffer, error] ¬ DoIOForOneRun[	  memBuffer, run.volumePage, VI.diskChannel, VI.firstPVPageOfLV,	  run.count, io];	dataError ¬ dataError OR error;	IF (countLeft ¬ (countLeft - CARDINAL[run.count])) > 0 THEN  	  page ¬ page + run.count	ELSE RETURN[dataError] };      startPage ¬ startPage + eTable.pageGroups[i].count;      i ¬ i + 1;      ENDLOOP;    END;    MinimalReadAndCorrect: PUBLIC PROCEDURE [    pageCount: CARDINAL, filePage: File.PageNumber,    copyETFET, primaryETFET: ETable.ETableHandle,     problem: VI.ETableErrorType, memBuffer: LONG POINTER]     RETURNS [    countToWrite: CARDINAL ¬ 0, firstOneToWrite: CARDINAL ¬ LAST[CARDINAL],    dataLost: BOOLEAN ¬ FALSE, copyUsed: BOOLEAN ¬ TRUE] =    BEGIN    currentMemPage: Environment.PageNumber ¬       Environment.PageFromLongPointer[memBuffer];    firstOne: BOOLEAN ¬ TRUE;    statusOfPrimary: DiskChannel.IOStatus ¬ goodCompletion;	    [] ¬ GatherRunsAndDoIO[copyETFET, memBuffer, filePage, pageCount, read];     -- Process page by page    FOR i: CARDINAL IN [0..pageCount) DO      IF ~VI.ValidPage[problem, currentMemPage] THEN         BEGIN        whichPage: Volume.PageNumber ¬	  ETI.WhereIsFilePageOnVolume[filePage+i, primaryETFET].volumePage;        copyUsed ¬ FALSE;        VI.AddToErrorList[File.nullID, copy, problem, i+filePage];        statusOfPrimary ¬ VI.ReadPage[	  whichPage, currentMemPage,VI.diskChannel,VI.firstPVPageOfLV];        IF (statusOfPrimary ~= goodCompletion OR 	  ~VI.ValidPage[problem,currentMemPage]) THEN 	  BEGIN	  dataLost ¬ TRUE;	  VI.AddToErrorList[File.nullID, primary, problem, i+filePage];	  countToWrite ¬ countToWrite + 1;	  END;	IF firstOne THEN {firstOne ¬ FALSE; firstOneToWrite ¬ i};	END;      currentMemPage ¬ currentMemPage + 1;      ENDLOOP;    END; --MinimalReadAndCorrect--      CleanOutETablesInBuckets: PROCEDURE [    bucketHandle: ETable.BucketHandle, bucketOffset: CARDINAL,     bucketsThisPass: CARDINAL, tok: VolTable.LVToken, lvHandle: LVF.Handle]     RETURNS [      countToWrite: CARDINAL ¬ 0, firstOffsetToWrite: CARDINAL ¬ LAST[CARDINAL]] =    BEGIN    bucketIONeeded: BOOLEAN;    firstBucket: BOOLEAN ¬ TRUE;    i: CARDINAL ¬ bucketOffset;    WHILE i # CARDINAL[bucketOffset+bucketsThisPass] DO      -- HOPEFULLY MinimalReadAndCorrect didn't alter the following value ?!      oldNumberOfFilesInFileList: CARDINAL ¬ VI.numberOfFilesInFileList;       currentETable: ETable.ETableHandle ¬ @bucketHandle.eTables[0];      VI.bucketOverflowList[i].oldCount ¬ 	 bucketHandle.header.eTablesInOverflowCount;      bucketIONeeded ¬ FALSE;      UNTIL currentETable =	 @bucketHandle[bucketHandle.header.firstFree] DO	 IF VI.ValidateETable[lvHandle, tok, currentETable] THEN	    BEGIN	    countToSmashAway: CARDINAL ¬ GetETableSize[currentETable];	    countToMove: CARDINAL ¬ CARDINAL[      	      @bucketHandle[bucketHandle.header.firstFree]	      - currentETable] - countToSmashAway;	    Inline.LongCOPY[	       from: currentETable + countToSmashAway, 	       nwords: countToMove,	       to: currentETable];	    bucketHandle.header.firstFree ¬ 	       bucketHandle.header.firstFree - countToSmashAway;	    bucketIONeeded ¬ TRUE;	    END	 ELSE currentETable ¬ currentETable + GetETableSize[currentETable];	 ENDLOOP;      IF bucketIONeeded THEN {        countToWrite ¬ countToWrite + 1;	IF firstBucket THEN {	  firstBucket ¬ FALSE; 	  firstOffsetToWrite ¬ i - bucketOffset}};      VI.numberOfFilesInFileList ¬ oldNumberOfFilesInFileList;      bucketHandle ¬ bucketHandle + Environment.wordsPerPage;      i ¬ i + 1;      ENDLOOP;     END;      FastVerify: PUBLIC PROCEDURE [lvbi: ETable.LVBucketInfo] =    BEGIN -- fast verifier    copyReferenced, dataLost: BOOLEAN;    firstOffsetToCorrect: CARDINAL;    interval: Space.Interval;    countToWrite, countCleaned, firstToClean: CARDINAL ¬ 0;    currentBucketPage: File.PageNumber ¬ lvbi.firstBucketPage;    countOfBucketsToDo: CARDINAL ¬       CARDINAL[lvbi.firstOverflowPage-lvbi.firstBucketPage];    bucketsPerPass: CARDINAL ¬ MIN[countOfBucketsToDo, 128]; --128 is a guess.    interval ¬ Space.Allocate[bucketsPerPass       ! Space.InsufficientSpace => { -- could be dangerous 	  bucketsPerPass ¬ MIN[bucketsPerPass/2, CARDINAL[available]]; RETRY}];    VM.ScratchMap[      [Space.PageFromLongPointer[interval.pointer], interval.count]];     WHILE (countOfBucketsToDo # 0) DO      BEGIN        ENABLE UNWIND =>	  BEGIN	  VM.Unmap[Space.PageFromLongPointer[interval.pointer] !	    Space.Error => CONTINUE];	  Space.Deallocate[interval ! Space.Error => CONTINUE];	  END;      [countToWrite, firstOffsetToCorrect, dataLost, copyReferenced] ¬ 	MinimalReadAndCorrect[	  bucketsPerPass, currentBucketPage, lvbi.copyETableHandle, 	  lvbi.primaryETableHandle, badBucketPage, interval.pointer];      IF dataLost THEN ERROR Scavenger.Error[bucketPageLost];      -- could have done it in tempfile process, maybe?      [countCleaned, firstToClean] ¬         CleanOutETablesInBuckets[	  interval.pointer, CARDINAL[currentBucketPage-lvbi.firstBucketPage], 	  bucketsPerPass, lvbi.token, lvbi.lvHandle];      countToWrite ¬ countToWrite + countCleaned;            IF (countToWrite # 0) OR (NOT copyReferenced) THEN        -- this means either there were temp files or the copy read was bad        BEGIN	count: CARDINAL;	firstOne: File.PageNumber;	memPointer: LONG POINTER;        firstOffsetToCorrect ¬ MIN[firstOffsetToCorrect, firstToClean];        firstOne ¬ firstOffsetToCorrect + currentBucketPage;	count ¬ bucketsPerPass - firstOffsetToCorrect;	memPointer ¬ 	  interval.pointer + firstOffsetToCorrect*Environment.wordsPerPage;	-- write out changed interval using countToWrite and firstOne as hints	SELECT TRUE FROM	  (countToWrite > 1) => { -- there were many buckets of temp files 	    [] ¬ GatherRunsAndDoIO[	      lvbi.primaryETableHandle, memPointer, firstOne, count, write];	    [] ¬ GatherRunsAndDoIO[	      lvbi.copyETableHandle, memPointer, firstOne, count, write]};	  ((countToWrite = 1) AND copyReferenced) => {-- one bucket of temp files 	    [] ¬ GatherRunsAndDoIO[	      lvbi.primaryETableHandle, memPointer, firstOne, 1, write];	    [] ¬ GatherRunsAndDoIO[	      lvbi.copyETableHandle, memPointer, firstOne, 1, write]};	 ((countToWrite = 1) AND NOT copyReferenced) => {	   -- bad copy, and one bucket of temp files (see countToWrite > 1 case)	    [] ¬ GatherRunsAndDoIO[	      lvbi.primaryETableHandle, memPointer, firstOne, count, write];	    [] ¬ GatherRunsAndDoIO[	      lvbi.copyETableHandle, memPointer, firstOne, count, write]};	 ((countToWrite = 0) AND NOT copyReferenced) =>  -- copy was bad, no temps	    [] ¬ GatherRunsAndDoIO[	      lvbi.copyETableHandle, memPointer, firstOne, count, write];	  ENDCASE => NULL;	END;            countOfBucketsToDo ¬ countOfBucketsToDo - bucketsPerPass;      currentBucketPage ¬ currentBucketPage + bucketsPerPass;      bucketsPerPass ¬ MIN[bucketsPerPass, countOfBucketsToDo];      END;      ENDLOOP;    VM.Unmap[Space.PageFromLongPointer[interval.pointer]];    Space.Deallocate[interval];    END; --fast verifier      END...    LOG			00-00-87  00:00:00	RRR	Created file.20-Nov-87  8:16:56	ET	Added GatherRunsAndDoIO, DoIOForOneRun, MinimalReadAndCorrect, CleanOutETablesInBuckets, and FastVerify for doing fast verifies. (AR 11895)15-Dec-87 12:48:58	ET	Added processing of badClientData in ProduceScavengerLog (AR 11896). Added more logic to countToWrite=1 arms in FastVerify and made sure firstOne defaults to LAST[CARDINAL] instead of 0. (AR 12453). 9-Jan-88 13:15:28	ET	Added badETableInBucket logic (AR 11904), forcing  client scavenges if etables were deleted because doesNotMakeSense=TRUE from ValidateETable. Added check in ProduceScavengerLog for errorListOverflowed relationship to incomplete state of log. (AR 12538). Fixed DoIOForOneRun to increment memBuffer/upDatedBuffer correctly (AR 12573).12-Jan-88  0:12:27      ET	Added MapMarkerPage, UnmapMarkerPage. (AR 12589).21-Jun-88 15:30:00      RSV     Changes to ProduceScavengerLog because ETable.PageGroupSeq changed its type.29-Jun-88 19:55:12      RSV     Changed CleanOutETablesInBuckets to represent fact that deleted is now returned from function ValidateETable.30-Jul-88 17:46:45      RSV     Fix for disabling mapped file locking.